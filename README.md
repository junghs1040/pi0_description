# Ï€â‚€ ëª¨ë¸ ë°ì´í„° íë¦„ Step-by-Step ì™„ì „ ê°€ì´ë“œ  
  
ì´ ë¬¸ì„œëŠ” Ï€â‚€ ëª¨ë¸ì—ì„œ **ì…ë ¥ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ì–´ ìµœì¢… ì¶œë ¥ì´ ë˜ëŠ”ì§€**ë¥¼ í•œ ë‹¨ê³„ì”© ì¶”ì í•©ë‹ˆë‹¤.  
  
> **ğŸ“Œ í•™ìŠµ vs ì¶”ë¡  êµ¬ë¶„**  
> ì´ ë¬¸ì„œëŠ” **í•™ìŠµ(Training)** ê³¼ì •ì„ ê¸°ë³¸ìœ¼ë¡œ ì„¤ëª…í•˜ë©°, ê° Stepì—ì„œ ì¶”ë¡    (Inference)ê³¼ ì°¨ì´ê°€ ìˆëŠ” ê²½ìš° `ğŸ”„ í•™ìŠµ vs ì¶”ë¡ ` ë°•ìŠ¤ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.  
> - ğŸ‹ï¸ **í•™ìŠµ**: Ground truth actions + noise â†’ Flow Matching loss ê³„ì‚°   
> - ğŸ¯ **ì¶”ë¡ **: Pure noiseì—ì„œ ì‹œì‘ â†’ 10íšŒ Euler integrationìœ¼ë¡œ action ìƒì„±  
  
Step 0: ì›ë³¸ ì…ë ¥ ë°ì´í„° (Images, State, Text, Actions)    
Step 1: Observation ê°ì²´ ìƒì„± (uint8 â†’ float32 ì •ê·œí™”)  
Step 2: Image Embedding (SigLIP) - 3Ã—256 = 768 tokens  
Step 3: Text Embedding (Gemma Embedder) - 16 tokens  
Step 4: Prefix Concatenation - 784 tokens (Image + Text)  
Step 5: Action Embedding (Suffix) - 33 tokens (State 1 + Action 32) + Flow Matching  
Step 6: Attention Mask ìƒì„± - [4, 817, 817]  
Step 7: Transformer Layer 0 ìƒì„¸ ë¶„ì„  
7-1: Pre-Attention RMSNorm  
7-2: QKV Projection (Multi-Expert)  
7-3: RoPE (Rotary Position Embedding)  
7-4: Grouped Query Attention  
7-5: Output Projection (Expertë³„)  
7-6: Residual Connection  
7-7: FeedForward Network  
Step 8: Transformer Layers 1-17 (18 layers total)  
Step 9: Final Layer Normalization  
Step 10-11: Velocity Prediction + Flow Matching Loss  
    

**ì˜ˆì‹œ ë°ì´í„°**:  
- Batch Size: B = 4  
- Images: 3ê°œ (base_0, left_wrist_0, right_wrist_0)  
- Text: 16 tokens  
- Actions: 32 timesteps, 7 DoF  
- Model: Ï€â‚€  
  
---

## ğŸ“ Step 0: ì›ë³¸ ì…ë ¥ ë°ì´í„°  

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 0: Raw Input (Python Dictionary)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

raw_input = {
    # â”€â”€â”€ Images â”€â”€â”€
    "image": {
        "base_0_rgb": np.array([4, 224, 224, 3], dtype=uint8),        # [0, 255]
        "left_wrist_0_rgb": np.array([4, 224, 224, 3], dtype=uint8),
        "right_wrist_0_rgb": np.array([4, 224, 224, 3], dtype=uint8),
    },
    "image_mask": {
        "base_0_rgb": np.array([True, True, True, True]),
        "left_wrist_0_rgb": np.array([True, True, True, True]),
        "right_wrist_0_rgb": np.array([True, True, True, True]),
    },

    # â”€â”€â”€ Robot State â”€â”€â”€
    "state": np.array([4, 7], dtype=float32),  # [x, y, z, qx, qy, qz, gripper]

    # â”€â”€â”€ Language Command â”€â”€â”€
    "tokenized_prompt": np.array([
        [15234, 67, 123, 9876, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # "pick up fork" + padding
        [8921, 456, 789, 234, 567, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # "grasp red cup" + padding
        [...],
        [...],
    ], dtype=int32),  # [4, 16]
    "tokenized_prompt_mask": np.array([
        [True, True, True, True, False, False, ...],  # ì²« 4ê°œë§Œ valid
        [True, True, True, True, True, False, ...],   # ì²« 5ê°œë§Œ valid
        [...],
        [...],
    ], dtype=bool),  # [4, 16]

    # â”€â”€â”€ Actions (Training only) â”€â”€â”€
    "actions": np.array([4, 32, 7], dtype=float32),  # Ground truth actions
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 0 ìš”ì•½:
ëª¨ë¸ì— ë“¤ì–´ê°€ëŠ” ì›ë³¸ ì…ë ¥ ë°ì´í„°ì˜ êµ¬ì¡°.
  - Images: 3ëŒ€ì˜ ì¹´ë©”ë¼ (base, left_wrist, right_wrist)ì—ì„œ ì°ì€ RGB ì˜ìƒ
  - State:  ë¡œë´‡ì˜ í˜„ì¬ ê´€ì ˆ ìƒíƒœ (x, y, z, ì¿¼í„°ë‹ˆì–¸, ê·¸ë¦¬í¼) 7 DoF
  - Text:   ì‚¬ëŒì´ ë‚´ë¦° ì–¸ì–´ ëª…ë ¹ ("pick up fork" ë“±) â†’ ì´ë¯¸ í† í¬ë‚˜ì´ì¦ˆëœ ì •ìˆ˜ ë°°ì—´
  - Actions: [í•™ìŠµ ì „ìš©] ì „ë¬¸ê°€ê°€ ìˆ˜í–‰í•œ Ground truth í–‰ë™ ì‹œí€€ìŠ¤
             ì¶”ë¡  ì‹œì—ëŠ” ì—†ìŒ â†’ noise ì—ì„œ ìƒì„±
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

> **ğŸ”„ í•™ìŠµ vs ì¶”ë¡ **
> | | í•™ìŠµ (Training) | ì¶”ë¡  (Inference) |
> |---|---|---|
> | **Images** | ë™ì¼ | ë™ì¼ |
> | **State** | ë™ì¼ | ë™ì¼ |
> | **Text** | ë™ì¼ | ë™ì¼ |
> | **Actions** | âœ… Ground truth í•„ìš” | âŒ ì—†ìŒ (noiseì—ì„œ ìƒì„±) |

---

## ğŸ“ Step 1: Observation ê°ì²´ ìƒì„±

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/model.py:110-125`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 1: Dictionary â†’ Observation Object
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

observation = Observation.from_dict(raw_input)

# â”€â”€â”€ ë‚´ë¶€ ì²˜ë¦¬ â”€â”€â”€
# 1. uint8 ì´ë¯¸ì§€ë¥¼ float32 [-1, 1]ë¡œ ì •ê·œí™”
for key in raw_input["image"]:
    image = raw_input["image"][key]  # [4, 224, 224, 3] uint8 [0, 255]
    image = image.astype(float32) / 255.0 * 2.0 - 1.0  # float32 [-1, 1]

# 2. êµ¬ì¡°í™”ëœ Observation ê°ì²´ ìƒì„±
observation = Observation(
    images={
        "base_0_rgb": [4, 224, 224, 3],        # float32, [-1, 1]
        "left_wrist_0_rgb": [4, 224, 224, 3],
        "right_wrist_0_rgb": [4, 224, 224, 3],
    },
    image_masks={
        "base_0_rgb": [4],        # bool
        "left_wrist_0_rgb": [4],
        "right_wrist_0_rgb": [4],
    },
    state=[4, 7],                              # float32
    tokenized_prompt=[4, 16],                  # int32
    tokenized_prompt_mask=[4, 16],             # bool
)

# âœ… Output Shape:
# - Images: 3ê°œ Ã— [4, 224, 224, 3] float32 [-1, 1]
# - State: [4, 7] float32
# - Text: [4, 16] int32

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 1 ìš”ì•½:
  ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì›ë³¸ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ Observation ê°ì²´ë¡œ ë³€í™˜.
  - uint8 [0,255] ì´ë¯¸ì§€ â†’ float32 [-1,1] ë¡œ ì •ê·œí™”
    (ëª¨ë¸ì´ ì—°ì†ì ì¸ ì‹¤ìˆ˜ê°’ ì…ë ¥ì„ ê¸°ëŒ€í•˜ê¸° ë•Œë¬¸)
  - ì´í›„ ëª¨ë“  ì²˜ë¦¬ëŠ” ì´ Observation ê°ì²´ë¥¼ í†µí•´ ì ‘ê·¼
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 2: Image Embedding (SigLIP)

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/pi0.py:113-125` + `src/openpi/models/siglip.py`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 2: Images â†’ Image Tokens (SigLIP Vision Encoder)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ê° ì´ë¯¸ì§€ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
image_tokens_list = []
for image_name in observation.images:
    image = observation.images[image_name]  # [4, 224, 224, 3]

    # â”€â”€â”€ SigLIP Forward Pass â”€â”€â”€
    image_tokens, _ = self.PaliGemma.img(image, train=False)

    # â”€â”€â”€ SigLIP ë‚´ë¶€ ì²˜ë¦¬ â”€â”€â”€
    # 2-1. Patch Embedding
    # Image [4, 224, 224, 3] â†’ 14Ã—14 patches
    patches = einops.rearrange(
        image,
        'b (h p1) (w p2) c -> b (h w) (p1 p2 c)',
        p1=14, p2=14
    )
    # patches: [4, 256, 588]  (256 = 16Ã—16, 588 = 14Ã—14Ã—3)

    patch_emb = nn.Dense(1152)(patches)  # [4, 256, 1152]

    # 2-2. Positional Embedding (Sinusoidal 2D)
    h, w = 16, 16  # 224/14 = 16
    y, x = jnp.mgrid[:h, :w]  # [16, 16]
    omega = jnp.arange(1152 // 4) / (1152 // 4 - 1)
    omega = 1.0 / (10000 ** omega)

    y_emb = jnp.einsum("m,d->md", y.flatten(), omega)  # [256, 288]
    x_emb = jnp.einsum("m,d->md", x.flatten(), omega)  # [256, 288]
    pos_emb = jnp.concatenate([
        jnp.sin(x_emb), jnp.cos(x_emb),
        jnp.sin(y_emb), jnp.cos(y_emb)
    ], axis=1)  # [256, 1152]

    x = patch_emb + pos_emb[None, :, :]  # [4, 256, 1152]

    # 2-3. Transformer Encoder (27 layers, So400m variant)
    for layer in range(27):
        # Pre-Norm
        x_norm = nn.LayerNorm()(x)

        # Multi-Head Self-Attention
        attn_out = nn.MultiHeadDotProductAttention(
            num_heads=16,  # 1152 / 16 = 72 per head
        )(x_norm, x_norm)  # [4, 256, 1152]

        x = x + attn_out  # Residual

        # Pre-Norm
        x_norm = nn.LayerNorm()(x)

        # MLP
        mlp_out = nn.Dense(4304)(x_norm)  # [4, 256, 4304]
        mlp_out = nn.gelu(mlp_out)
        mlp_out = nn.Dense(1152)(mlp_out)  # [4, 256, 1152]

        x = x + mlp_out  # Residual

    # 2-4. Final Projection to PaliGemma dimension
    image_tokens = nn.Dense(2048)(x)  # [4, 256, 2048]

    image_tokens_list.append(image_tokens)

# âœ… Output:
# image_tokens_list = [
#     [4, 256, 2048],  # base_0_rgb
#     [4, 256, 2048],  # left_wrist_0_rgb
#     [4, 256, 2048],  # right_wrist_0_rgb
# ]
# Total: 3 Ã— 256 = 768 image tokens

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 2 ìš”ì•½:
  SigLIP (ViT-So400m/14) ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ í† í° ì‹œí€€ìŠ¤ë¡œ ë³€í™˜.
  - 224Ã—224 ì´ë¯¸ì§€ë¥¼ 14Ã—14 í¬ê¸°ì˜ íŒ¨ì¹˜ 256ê°œë¡œ ë¶„í• 
  - 27ì¸µ ViT Transformerë¡œ ê° íŒ¨ì¹˜ì˜ ë¬¸ë§¥ì  íŠ¹ì§• ì¶”ì¶œ (width=1152)
  - ìµœì¢… Dense(2048) ë¡œ PaliGemma ì˜ ì–¸ì–´ ëª¨ë¸ ì°¨ì›ì— ë§ê²Œ íˆ¬ì˜
  - 3ê°œ ì¹´ë©”ë¼ ê°ê° ë…ë¦½ ì²˜ë¦¬ â†’ 768ê°œì˜ ì´ë¯¸ì§€ í† í° ìƒì„±
  - ì´ í† í°ë“¤ì´ ì–¸ì–´ í† í°ê³¼ ë™ì¼í•œ ì„ë² ë”© ê³µê°„ì— ë†“ì´ê²Œ ë¨
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 3: Text Embedding (Gemma Embedder)

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:148-154` + `pi0.py:128-133`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 3: Token IDs â†’ Text Embeddings
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ì…ë ¥: observation.tokenized_prompt
# [4, 16] int32
tokenized_prompt = observation.tokenized_prompt

# â”€â”€â”€ Embedder.encode() â”€â”€â”€
tokenized_inputs = self.PaliGemma.llm(tokenized_prompt, method="embed")

# â”€â”€â”€ Embedder ë‚´ë¶€ â”€â”€â”€
class Embedder:
    def encode(self, x):
        # 1. Embedding table lookup
        # input_embedding_table: [257152, 2048]
        x = self.input_embedding_table[(x,)]  # [4, 16, 2048]

        # 2. Scale by âˆšembed_dim (Attention Is All You Need ë…¼ë¬¸)
        x *= jnp.sqrt(2048)  # â‰ˆ 45.25
        # ì´ìœ : Embedding ê°’ì˜ scaleì„ ì¡°ì •í•˜ì—¬ position encodingê³¼ ê· í˜•

        return x  # [4, 16, 2048]

# âœ… Output:
# text_tokens: [4, 16, 2048]
#
# ì˜ˆì‹œ ë³€í™˜:
# Token ID 15234 â†’ embedding_table[15234] â†’ [2048 dims] Ã— 45.25
# Token ID 67    â†’ embedding_table[67]    â†’ [2048 dims] Ã— 45.25
# Token ID 0     â†’ embedding_table[0]     â†’ [2048 dims] Ã— 45.25 (padding)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 3 ìš”ì•½:
  ì •ìˆ˜ í† í° IDë¥¼ ì—°ì†ì ì¸ 2048ì°¨ì› ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜.
  - ì–´íœ˜ í¬ê¸° 257,152ê°œì˜ ë£©ì—… í…Œì´ë¸”ì—ì„œ í•´ë‹¹ í–‰ì„ ê°€ì ¸ì˜´
  - âˆš2048 â‰ˆ 45.25 ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ì„ë² ë”© í¬ê¸°ë¥¼ ì•ˆì •í™”
    (ì´ë¯¸ì§€ í† í°ê³¼ ì–¸ì–´ í† í°ì´ ê°™ì€ ìˆ˜ì¹˜ ë²”ìœ„ì— ìˆë„ë¡ ë§ì¶¤)
  - ì´ ì‹œì ì—ì„œ ì´ë¯¸ì§€ í† í°ê³¼ í…ìŠ¤íŠ¸ í† í°ì€ ë™ì¼í•œ [B, S, 2048] í˜•íƒœë¥¼ ê°€ì§
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 4: Prefix Token Concatenation

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/pi0.py:106-137`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 4: Image + Text â†’ Prefix Sequence
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def embed_prefix(self, obs):
    tokens = []
    input_mask = []
    ar_mask = []

    # â”€â”€â”€ 4-1: Image tokens ì¶”ê°€ â”€â”€â”€
    for name in obs.images:
        image_tokens = image_tokens_list.pop(0)  # [4, 256, 2048]
        tokens.append(image_tokens)

        # Mask: ëª¨ë“  image tokenì€ valid
        mask = einops.repeat(
            obs.image_masks[name],  # [4]
            "b -> b s",
            s=256
        )  # [4, 256]
        input_mask.append(mask)

        # AR Mask: imageëŠ” bidirectional attention
        ar_mask += [False] * 256

    # â”€â”€â”€ 4-2: Text tokens ì¶”ê°€ â”€â”€â”€
    if obs.tokenized_prompt is not None:
        text_tokens = tokenized_inputs  # [4, 16, 2048]
        tokens.append(text_tokens)
        input_mask.append(obs.tokenized_prompt_mask)  # [4, 16]

        # AR Mask: textë„ bidirectional attention
        ar_mask += [False] * 16

    # â”€â”€â”€ 4-3: Concatenation â”€â”€â”€
    prefix_tokens = jnp.concatenate(tokens, axis=1)
    # [4, 768, 2048] + [4, 16, 2048] = [4, 784, 2048]

    prefix_mask = jnp.concatenate(input_mask, axis=1)  # [4, 784]
    prefix_ar_mask = jnp.array(ar_mask)  # [784]

    return prefix_tokens, prefix_mask, prefix_ar_mask

# âœ… Output:
# - prefix_tokens: [4, 784, 2048]
#   â”œâ”€ Image 0: tokens[0:256]
#   â”œâ”€ Image 1: tokens[256:512]
#   â”œâ”€ Image 2: tokens[512:768]
#   â””â”€ Text:    tokens[768:784]
# - prefix_mask: [4, 784] (all True)
# - prefix_ar_mask: [784] (all False = bidirectional)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 4 ìš”ì•½:
  ì´ë¯¸ì§€ í† í°(768ê°œ)ê³¼ í…ìŠ¤íŠ¸ í† í°(16ê°œ)ì„ í•˜ë‚˜ì˜ Prefix ì‹œí€€ìŠ¤ë¡œ í•©ì¹¨.
  - ìˆœì„œ: [image_0(256), image_1(256), image_2(256), text(16)] = 784 í† í°
  - ar_mask = ì „ë¶€ False â†’ Prefix ë‚´ë¶€ëŠ” ëª¨ë“  í† í°ì´ ì„œë¡œë¥¼ ë³¼ ìˆ˜ ìˆëŠ” ì–‘ë°©í–¥ attention
  - ì´ PrefixëŠ” "í™˜ê²½ ê´€ì°° ì •ë³´" ì „ì²´ë¥¼ ë‹´ìŒ
  - ì¶”ë¡  ì‹œ ì´ 784ê°œ í† í°ì€ KV Cacheë¡œ ì €ì¥ë˜ì–´ í•œ ë²ˆë§Œ ê³„ì‚°ë¨
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 5: Action Embedding (Suffix)

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/pi0.py:139-186`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 5: State + Actions â†’ Suffix Tokens (Ï€â‚€ ë°©ì‹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Training input: ground truth actions
actions = raw_input["actions"]  # [4, 32, 7]
state = observation.state       # [4, 7]

# â”€â”€â”€ 5-1: Flow Matching Preparation â”€â”€â”€
noise = jax.random.normal(noise_rng, actions.shape)  # [4, 32, 7]

# Timestep ìƒ˜í”Œë§ (Beta distribution, t=1ì´ noise, t=0ì´ data)
time = jax.random.beta(time_rng, 1.5, 1.0, batch_shape=[4])
# time: [4]  ì˜ˆ: [0.234, 0.891, 0.456, 0.123]

# Flow interpolation: x_t = tÂ·noise + (1-t)Â·actions
time_expanded = time[:, None, None]  # [4, 1, 1]
x_t = time_expanded * noise + (1 - time_expanded) * actions
# x_t: [4, 32, 7]

# Target velocity (ì§ì„  ê²½ë¡œì´ë¯€ë¡œ ìƒìˆ˜)
u_t = noise - actions  # [4, 32, 7]

# â”€â”€â”€ 5-2: State Token (Ï€â‚€ ì „ìš©) â”€â”€â”€
# stateë¥¼ 1ê°œì˜ í† í°ìœ¼ë¡œ projection
state_token = self.state_proj(state)[:, None, :]
# Linear(7 â†’ 1024)
# [4, 7] â†’ [4, 1024] â†’ [4, 1, 1024]

# â”€â”€â”€ 5-3: Action Token Projection â”€â”€â”€
action_tokens = self.action_in_proj(x_t)
# Linear(7 â†’ 1024)
# [4, 32, 7] â†’ [4, 32, 1024]

# â”€â”€â”€ 5-4: Timestep Embedding (Sinusoidal) â”€â”€â”€
def posemb_sincos(pos, embedding_dim, min_period, max_period):
    # pos: [4], embedding_dim: 1024
    fraction = jnp.linspace(0.0, 1.0, embedding_dim // 2)  # [512]
    period = min_period * (max_period / min_period) ** fraction
    # period: [0.004, ..., 4.0]

    sinusoid_input = jnp.einsum(
        "i,j->ij",
        pos,            # [4]
        1.0 / period * 2 * jnp.pi  # [512]
    )  # [4, 512]

    emb = jnp.concatenate([
        jnp.sin(sinusoid_input),  # [4, 512]
        jnp.cos(sinusoid_input),  # [4, 512]
    ], axis=-1)  # [4, 1024]

    return emb

time_emb = posemb_sincos(time, 1024, min_period=4e-3, max_period=4.0)
# time_emb: [4, 1024]

# â”€â”€â”€ 5-5: Action + Time ê²°í•© MLP (Ï€â‚€ ë°©ì‹) â”€â”€â”€
# timestep ì„ë² ë”©ì„ action_horizonë§Œí¼ ë³µì œ
time_tokens = einops.repeat(time_emb, "b emb -> b s emb", s=32)
# [4, 1024] â†’ [4, 32, 1024]

# actionê³¼ timeì„ concat
action_time_tokens = jnp.concatenate([action_tokens, time_tokens], axis=-1)
# [4, 32, 1024] + [4, 32, 1024] = [4, 32, 2048]

# MLPë¡œ ì••ì¶•
action_time_tokens = self.action_time_mlp_in(action_time_tokens)
# Linear(2048 â†’ 1024): [4, 32, 2048] â†’ [4, 32, 1024]
action_time_tokens = nnx.swish(action_time_tokens)
action_time_tokens = self.action_time_mlp_out(action_time_tokens)
# Linear(1024 â†’ 1024): [4, 32, 1024] â†’ [4, 32, 1024]
action_expert_tokens = action_time_tokens  # [4, 32, 1024]

# â”€â”€â”€ 5-6: Suffix êµ¬ì„± â”€â”€â”€
# state token + action tokens concat
suffix_tokens = jnp.concatenate([state_token, action_expert_tokens], axis=1)
# [4, 1, 1024] + [4, 32, 1024] = [4, 33, 1024]

suffix_mask = jnp.ones([4, 33], dtype=bool)  # ëª¨ë‘ valid

# AR Mask:
# - state í† í°: [True]          â† prefixê°€ stateë¥¼ ë³¼ ìˆ˜ ì—†ìŒ
# - ì²« action í† í°: [True]      â† stateê°€ actionì„ ë³¼ ìˆ˜ ì—†ìŒ
# - ë‚˜ë¨¸ì§€ action í† í°: [FalseÃ—31] â† actionë¼ë¦¬ ì–‘ë°©í–¥ attention
suffix_ar_mask = jnp.array([True] + [True] + [False] * 31)
# [True, True, False, False, ..., False]
#  state  act0  act1  ...        act31

# âœ… Output:
# - suffix_tokens: [4, 33, 1024]
#   â”œâ”€ state:   tokens[0]     â† 1ê°œ
#   â””â”€ actions: tokens[1:33]  â† 32ê°œ
# - suffix_mask: [4, 33] (all True)
# - suffix_ar_mask: [33] ([True, True, FalseÃ—31])
# - adarms_cond: None (Ï€â‚€ëŠ” AdaRMS ì‚¬ìš© ì•ˆ í•¨)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 5 ìš”ì•½:
  ë¡œë´‡ stateì™€ (ë…¸ì´ì¦ˆ ì„ì¸) actionì„ Action Expert ì°¨ì›(1024)ìœ¼ë¡œ ì„ë² ë”©.
  - State:  Linear(7â†’1024) â†’ 1ê°œì˜ state í† í°
  - Action: Linear(7â†’1024) â†’ 32ê°œì˜ action í† í°
  - Time:   sincos PEë¡œ ìŠ¤ì¹¼ë¼ t â†’ 1024ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
            action í† í°ê³¼ concat í›„ MLP â†’ ì‹œê°„ ì •ë³´ë¥¼ action ì„ë² ë”©ì— í˜¼í•©
  - Flow Matching: x_t = tÂ·noise + (1-t)Â·actions  (í•™ìŠµ ì‹œ ì¤‘ê°„ ìƒíƒœ ìƒì„±)
  - suffix = [state(1), action(32)] = 33 í† í°
  - ar_mask: [True, True, FalseÃ—31]
    â†’ state(cumsum=1)ëŠ” action(cumsum=2)ì„ ë³¼ ìˆ˜ ì—†ìŒ
    â†’ actionë¼ë¦¬ëŠ” ì–‘ë°©í–¥ attention (cumsum=2 ë¼ë¦¬ ë™ì¼)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

> **ğŸ”„ í•™ìŠµ vs ì¶”ë¡ **
> | | í•™ìŠµ (Training) | ì¶”ë¡  (Inference) |
> |---|---|---|
> | **ì…ë ¥ actions** | Ground truth actions | ì—†ìŒ (noiseì—ì„œ ì‹œì‘) |
> | **Noise** | `noise ~ N(0, I)` | `noise ~ N(0, I)` (= ì´ˆê¸° x_t) |
> | **Timestep t** | `t ~ Beta(1.5, 1.0)` ëœë¤ ìƒ˜í”Œë§ | `t = 1.0, 0.9, ..., 0.1` ê³ ì • ìŠ¤ì¼€ì¤„ |
> | **x_t ê³„ì‚°** | `x_t = tÂ·noise + (1-t)Â·actions` (interpolation) | ë°˜ë³µë§ˆë‹¤ Euler stepìœ¼ë¡œ ì—…ë°ì´íŠ¸ |
> | **íšŸìˆ˜** | **1íšŒ** (í•œ ë²ˆì˜ forward pass) | **10íšŒ** ë°˜ë³µ (ë§¤ë²ˆ suffix ì¬ìƒì„±) |
>
> í•™ìŠµì—ì„œëŠ” ëœë¤ të¡œ interpolated sampleì„ ë§Œë“¤ì§€ë§Œ, ì¶”ë¡ ì—ì„œëŠ” t=1.0(pure noise)ì—ì„œ ì‹œì‘í•˜ì—¬ ë§¤ stepë§ˆë‹¤ velocityë¥¼ ì˜ˆì¸¡í•˜ê³  `x_{t+dt} = x_t + dtÂ·v_t`ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

---

## ğŸ“ Step 6: Attention Mask ìƒì„±

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/pi0.py:19-44` + `202-208`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 6: Create Attention Mask
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€ 6-1: Concatenate masks â”€â”€â”€
input_mask = jnp.concatenate([prefix_mask, suffix_mask], axis=1)
# [4, 784] + [4, 33] = [4, 817]

ar_mask = jnp.concatenate([prefix_ar_mask, suffix_ar_mask], axis=0)
# [784] + [33] = [817]
# ar_mask = [FalseÃ—784, True, True, FalseÃ—31]
#            ^^^^^^^^    ^     ^     ^^^^^^^^
#            Prefix      state act0  act1~31

# â”€â”€â”€ 6-2: cumsumìœ¼ë¡œ ê·¸ë£¹ ë¶„ë¦¬ â”€â”€â”€
cumsum = jnp.cumsum(ar_mask, axis=1)
# [0Ã—784, 1, 2, 2Ã—31]
#  Prefix  st act0 act1~31
# â†’ ê·¸ë£¹ 0: prefix
# â†’ ê·¸ë£¹ 1: state
# â†’ ê·¸ë£¹ 2: action (ëª¨ë‘ ë™ì¼, ì–‘ë°©í–¥)

# â”€â”€â”€ 6-3: Generate Attention Mask â”€â”€â”€
def make_attn_mask(input_mask, mask_ar):
    mask_ar = jnp.broadcast_to(mask_ar, input_mask.shape)  # [4, 817]
    cumsum = jnp.cumsum(mask_ar, axis=1)
    attn_mask = cumsum[:, None, :] <= cumsum[:, :, None]
    # cumsum[key] <= cumsum[query] ì´ë©´ queryê°€ keyë¥¼ ë³¼ ìˆ˜ ìˆìŒ
    valid_mask = input_mask[:, None, :] * input_mask[:, :, None]
    return jnp.logical_and(attn_mask, valid_mask)

attn_mask = make_attn_mask(input_mask, ar_mask)
# attn_mask: [4, 817, 817]

# â”€â”€â”€ 6-4: Attention íŒ¨í„´ ì‹œê°í™” â”€â”€â”€
"""
Attention pattern [817, 817]:

                  Prefix(784)        State(1)  Actions(32)
              cumsum=0               cumsum=1  cumsum=2
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Prefix   â”‚  âœ“  âœ“  âœ“  ...  âœ“   â”‚    âœ—     â”‚  âœ—  ...  âœ— â”‚ cumsum=0
(0-783)  â”‚  (ì–‘ë°©í–¥)             â”‚          â”‚            â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
State    â”‚  âœ“  âœ“  âœ“  ...  âœ“   â”‚    âœ“     â”‚  âœ—  ...  âœ— â”‚ cumsum=1
(784)    â”‚  prefix ì°¸ì¡° ê°€ëŠ¥     â”‚  ìê¸°ìì‹   â”‚            â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Actions  â”‚  âœ“  âœ“  âœ“  ...  âœ“   â”‚    âœ“     â”‚  âœ“  ...  âœ“ â”‚ cumsum=2
(785-816)â”‚  prefix ì°¸ì¡° ê°€ëŠ¥     â”‚  stateì°¸ì¡°â”‚  (ì–‘ë°©í–¥)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ê·œì¹™: cumsum[key] <= cumsum[query] â†’ ì°¸ì¡° ê°€ëŠ¥
  prefixâ†’prefix:   0<=0 âœ“ ì–‘ë°©í–¥
  prefixâ†’state:    1<=0 âœ— ì°¨ë‹¨
  prefixâ†’action:   2<=0 âœ— ì°¨ë‹¨
  stateâ†’prefix:    0<=1 âœ“
  stateâ†’state:     1<=1 âœ“
  stateâ†’action:    2<=1 âœ— ì°¨ë‹¨
  actionâ†’prefix:   0<=2 âœ“
  actionâ†’state:    1<=2 âœ“
  actionâ†’action:   2<=2 âœ“ ì–‘ë°©í–¥
"""

# â”€â”€â”€ 6-5: Position Encoding â”€â”€â”€
positions = jnp.cumsum(input_mask, axis=1) - 1
# [4, 817]
# Example: [[0, 1, 2, ..., 783, 784, 785, ..., 816], ...]

# âœ… Output:
# - attn_mask: [4, 817, 817] bool
# - positions: [4, 817] int32

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 6 ìš”ì•½:
  ì–´ë–¤ í† í°ì´ ì–´ë–¤ í† í°ì„ ë³¼ ìˆ˜ ìˆëŠ”ì§€ ê²°ì •í•˜ëŠ” [817,817] ë§ˆìŠ¤í¬ ìƒì„±.
  - ar_maskë¥¼ cumsumìœ¼ë¡œ ê·¸ë£¹í™”: prefix(0) / state(1) / action(2)
  - ê·œì¹™: cumsum[key] <= cumsum[query] ì´ë©´ ì°¸ì¡° ê°€ëŠ¥
    â†’ prefixë¼ë¦¬ ì–‘ë°©í–¥  (0<=0)
    â†’ actionâ†’prefix ê°€ëŠ¥ (0<=2), prefixâ†’action ë¶ˆê°€ (2<=0 âœ—)
    â†’ actionâ†’state ê°€ëŠ¥  (1<=2), stateâ†’action ë¶ˆê°€  (2<=1 âœ—)
    â†’ actionë¼ë¦¬ ì–‘ë°©í–¥  (2<=2)
  - ì´ ì„¤ê³„ì˜ í•µì‹¬: prefixëŠ” suffixì— ì˜í–¥ë°›ì§€ ì•ŠìŒ
    â†’ ì¶”ë¡  ì‹œ prefix KV Cacheë¥¼ ì•ˆì „í•˜ê²Œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê·¼ê±°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 7: Multi-Expert Transformer Layer 0

ì´ì œ 18ê°œì˜ Transformer layer ì¤‘ **ì²« ë²ˆì§¸ layer**ë¥¼ ìì„¸íˆ ë´…ë‹ˆë‹¤.

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:284-333`

### Step 7-1: Pre-Attention RMSNorm

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 7-1: Pre-Attention RMSNorm
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ì…ë ¥:
xs = [prefix_tokens, suffix_tokens]
# xs[0]: [4, 784, 2048]  (Expert 0 - PaliGemma, width=2048)
# xs[1]: [4, 33, 1024]   (Expert 1 - Action Expert, width=1024)

adarms_cond = [None, None]
# Ï€â‚€ëŠ” AdaRMS ì‚¬ìš© ì•ˆ í•¨ â†’ ë‘˜ ë‹¤ None

# â”€â”€â”€ RMSNorm ì ìš© (ë‘ expert ëª¨ë‘ ë™ì¼í•œ ë°©ì‹) â”€â”€â”€
pre_attn = []
gates = []

for i, x in enumerate(xs):
    if x is not None:
        # 1. Root Mean Square ê³„ì‚°
        var = jnp.mean(jnp.square(x.astype(float32)), axis=-1, keepdims=True)
        # xs[0]: [4, 784, 2048] â†’ var: [4, 784, 1]
        # xs[1]: [4, 33, 1024]  â†’ var: [4, 33, 1]

        # 2. Normalization
        normed_inputs = x * jnp.reciprocal(jnp.sqrt(var + 1e-6))

        # 3. Regular RMSNorm (ë‘ expert ëª¨ë‘ ë™ì¼)
        scale = self.param("scale", zeros_init(), (x.shape[-1],))
        # Expert 0: scale [2048]
        # Expert 1: scale [1024]
        x_norm = normed_inputs * (1 + scale)
        gate = None  # Ï€â‚€ëŠ” gate ì—†ìŒ

        pre_attn.append(x_norm)
        gates.append(gate)

# âœ… Output:
# pre_attn[0]: [4, 784, 2048]  (Normalized prefix)
# pre_attn[1]: [4, 33, 1024]   (Normalized suffix)
# gates = [None, None]          (Ï€â‚€ëŠ” gate ì—†ìŒ)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 7-1 ìš”ì•½:
  Attention ì „ì— ê° expertì˜ ì…ë ¥ì„ ë…ë¦½ì ìœ¼ë¡œ ì •ê·œí™”.
  - Expert 0 (PaliGemma): scale íŒŒë¼ë¯¸í„° í¬ê¸° [2048]
  - Expert 1 (Action Expert): scale íŒŒë¼ë¯¸í„° í¬ê¸° [1024]
  - ë‘ expert ëª¨ë‘ ì¼ë°˜ RMSNorm ì‚¬ìš© (Ï€â‚€ëŠ” AdaRMS ì—†ìŒ)
  - RMSNorm: ê° í† í° ë²¡í„°ì˜ RMSë¡œ ë‚˜ëˆ„ì–´ í¬ê¸°ë¥¼ ë§ì¶¤
    (LayerNormê³¼ ë‹¬ë¦¬ í‰ê·  ë¹¼ê¸° ì—†ì´ ë¶„ì‚°ë§Œ ì •ê·œí™”)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Step 7-2: QKV Projection (Multi-Expert)

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:158-199`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 7-2: QKV Projection (Expert-specific Weights)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# head_dim=256, num_heads=8, num_kv_heads=1 ì€ ë‘ expert ê³µí†µ

qkvs = []

# â”€â”€â”€ Expert 0 (PaliGemma, width=2048) â”€â”€â”€
q_einsum_0 = Einsum(shape=(8, 2048, 256), name="q_einsum")
q_0 = q_einsum_0("BTD,NDH->BTNH", pre_attn[0])
# [4, 784, 2048] â†’ q_0: [4, 784, 8, 256]

kv_einsum_0 = Einsum(shape=(2, 1, 2048, 256), name="kv_einsum")
k_0, v_0 = kv_einsum_0("BSD,2KDH->2BSKH", pre_attn[0])
# k_0, v_0: [4, 784, 1, 256]

qkvs.append((q_0, k_0, v_0))

# â”€â”€â”€ Expert 1 (Action Expert, width=1024) â”€â”€â”€
q_einsum_1 = Einsum(shape=(8, 1024, 256), name="q_einsum_1")  # â† width=1024!
q_1 = q_einsum_1("BTD,NDH->BTNH", pre_attn[1])
# [4, 33, 1024] â†’ q_1: [4, 33, 8, 256]

kv_einsum_1 = Einsum(shape=(2, 1, 1024, 256), name="kv_einsum_1")  # â† width=1024!
k_1, v_1 = kv_einsum_1("BSD,2KDH->2BSKH", pre_attn[1])
# k_1, v_1: [4, 33, 1, 256]

qkvs.append((q_1, k_1, v_1))

# âœ… Output:
# qkvs[0]: (q[4,784,8,256], k[4,784,1,256], v[4,784,1,256]) â† 2048â†’256
# qkvs[1]: (q[4,33,8,256],  k[4,33,1,256],  v[4,33,1,256])  â† 1024â†’256
#          ^^^ ì…ë ¥ ì°¨ì›ì€ ë‹¤ë¥´ì§€ë§Œ, ì¶œë ¥(head_dim=256)ì€ ê°™ìŒ!

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 7-2 ìš”ì•½:
  ê° expertê°€ ì„œë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¡œ QKVë¥¼ ê³„ì‚°í•˜ë˜, ì¶œë ¥ head_dim=256ì€ í†µì¼.
  - Expert 0: 2048 â†’ 256 (Q: 8heads, K/V: 1head)
  - Expert 1: 1024 â†’ 256 (Q: 8heads, K/V: 1head)
  - ë‹¤ë¥¸ ì…ë ¥ ì°¨ì›ì„ ê°™ì€ attention ê³µê°„ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” í•µì‹¬ ë‹¨ê³„
  - K/V head ìˆ˜=1 (Grouped Query Attention): ë©”ëª¨ë¦¬ ì ˆì•½
    â†’ 8ê°œ Qê°€ 1ê°œ K,Vë¥¼ ê³µìœ  â†’ 8ë°° ë©”ëª¨ë¦¬ ì ˆì•½
  - ì´ projection í›„ Q,K,Vë¥¼ concatí•˜ì—¬ shared attention ê³„ì‚° ê°€ëŠ¥
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Step 7-3: RoPE (Rotary Position Embedding)

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:424-440`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 7-3: Apply RoPE to Q and K
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ë‘ expertì˜ QKVë¥¼ sequence ì¶•ìœ¼ë¡œ concat â†’ ê°™ì€ 256 ì°¨ì›ìœ¼ë¡œ í•©ì³ì§
q, k, v = (jnp.concatenate(y, axis=1) for y in zip(*qkvs))
# q: [4, 817, 8, 256]  (784 + 33)
# k: [4, 817, 1, 256]
# v: [4, 817, 1, 256]

def _apply_rope(x, positions, max_wavelength=10_000):
    freq_exponents = (2.0 / 256) * jnp.arange(256 // 2)  # [128]
    timescale = max_wavelength ** freq_exponents

    radians = positions[..., None] / timescale[None, None, :]
    # [4, 817, 128]
    radians = radians[..., None, :]  # [4, 817, 1, 128]

    sin, cos = jnp.sin(radians), jnp.cos(radians)
    x1, x2 = jnp.split(x, 2, axis=-1)

    res = jnp.concatenate([
        x1 * cos - x2 * sin,
        x2 * cos + x1 * sin,
    ], axis=-1)  # [4, 817, H, 256]

    return res

q = _apply_rope(q, positions=positions)  # [4, 817, 8, 256]
k = _apply_rope(k, positions=positions)  # [4, 817, 1, 256]
q *= 256 ** -0.5  # scale by 1/âˆšhead_dim

# âœ… Output:
# q: [4, 817, 8, 256]
# k: [4, 817, 1, 256]
# v: [4, 817, 1, 256]

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 7-3 ìš”ì•½:
  ë‘ expertì˜ QKVë¥¼ ì‹œí€€ìŠ¤ ì¶•ìœ¼ë¡œ concat í›„ ìœ„ì¹˜ ì¸ì½”ë”© ì ìš©.
  - concat: prefix(784) + suffix(33) = 817 í† í°ìœ¼ë¡œ í•©ì³ì§
    â†’ ì´ ì‹œì ë¶€í„° ë‘ expertì˜ í† í°ì´ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ ì²˜ë¦¬ë¨ (Shared Attention)
  - RoPE: ì ˆëŒ€ ìœ„ì¹˜ ì¸ì½”ë”©ê³¼ ë‹¬ë¦¬ Q,Kì—ë§Œ íšŒì „ ë³€í™˜ì„ ì ìš©
    â†’ í† í° ê°„ ìƒëŒ€ ìœ„ì¹˜ê°€ ë‚´ì (attention score)ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜ë¨
  - qì— 1/âˆš256 ìŠ¤ì¼€ì¼ë§: softmax ì „ ê°’ì´ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ì•ˆì •í™”
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Step 7-4: Grouped Query Attention

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:216-231`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 7-4: Grouped Query Attention (GQA)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Reshape Q for GQA: num_heads=8, num_kv_heads=1, group_size=8
q = einops.rearrange(q, "B T (K G) H -> B T K G H", K=1)
# [4, 817, 8, 256] â†’ [4, 817, 1, 8, 256]

# Attention scores
logits = jnp.einsum("BTKGH,BSKH->BKGTS", q, k)
# q: [4, 817, 1, 8, 256]
# k: [4, 817, 1, 256]
# logits: [4, 1, 8, 817, 817]

# Apply attention mask
big_neg = -2.3819763e38
attn_mask_expanded = attn_mask[:, None, None, :, :]
# [4, 817, 817] â†’ [4, 1, 1, 817, 817]

masked_logits = jnp.where(attn_mask_expanded, logits, big_neg)

probs = jax.nn.softmax(masked_logits, axis=-1).astype(dtype)
# probs: [4, 1, 8, 817, 817]

encoded = jnp.einsum("BKGTS,BSKH->BTKGH", probs, v)
# encoded: [4, 817, 1, 8, 256]

encoded = einops.rearrange(encoded, "B T K G H -> B T (K G) H")
# [4, 817, 8, 256]

# âœ… Output:
# encoded: [4, 817, 8, 256]  (attention-weighted values)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 7-4 ìš”ì•½:
  817ê°œ ì „ì²´ í† í°(prefix+suffix)ì— ëŒ€í•´ attention ê³„ì‚°.
  - Step 6ì—ì„œ ë§Œë“  [817,817] ë§ˆìŠ¤í¬ë¥¼ ì ìš©
    â†’ í—ˆìš©ë˜ì§€ ì•Šì€ ìœ„ì¹˜ëŠ” -âˆë¡œ ì„¤ì • â†’ softmax í›„ í™•ë¥  0
  - ë‘ expertì˜ í† í°ì´ í•˜ë‚˜ì˜ attention í–‰ë ¬ì„ ê³µìœ 
    â†’ Action Expert í† í°ì´ PaliGemma í† í°(ì´ë¯¸ì§€/ì–¸ì–´)ì„ ì§ì ‘ ì°¸ì¡° ê°€ëŠ¥
  - ì´ê²ƒì´ Transfusion êµ¬ì¡°ì˜ í•µì‹¬:
    ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°(ì–¸ì–´, ì´ë¯¸ì§€, í–‰ë™)ê°€ í•˜ë‚˜ì˜ attentionì—ì„œ ìƒí˜¸ì‘ìš©
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Step 7-5: Output Projection (Multi-Expert)

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:233-249`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 7-5: Output Projection (Expertë³„ ë…ë¦½)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# encoded: [4, 817, 8, 256] (ëª¨ë“  í† í°ì˜ attention output)

out = []
start = 0

# â”€â”€â”€ Expert 0 (PaliGemma) â”€â”€â”€
end = 784
expert_encoded_0 = encoded[:, start:end]  # [4, 784, 8, 256]
out_einsum_0 = Einsum(
    shape=(8, 256, 2048),  # (num_heads, head_dim, width)
    name="attn_vec_einsum"
)
expert_out_0 = out_einsum_0("BTNH,NHD->BTD", expert_encoded_0)
# [4, 784, 2048]
out.append(expert_out_0)
start = end  # 784

# â”€â”€â”€ Expert 1 (Action Expert) â”€â”€â”€
end = 817
expert_encoded_1 = encoded[:, start:end]  # [4, 33, 8, 256]
out_einsum_1 = Einsum(
    shape=(8, 256, 1024),  # â† width=1024!
    name="attn_vec_einsum_1"
)
expert_out_1 = out_einsum_1("BTNH,NHD->BTD", expert_encoded_1)
# [4, 33, 1024]
out.append(expert_out_1)

# âœ… Output:
# out[0]: [4, 784, 2048]  (Prefix, Expert 0 weight ì‚¬ìš©)
# out[1]: [4, 33, 1024]   (Suffix, Expert 1 weight ì‚¬ìš©)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 7-5 ìš”ì•½:
  ê³µìœ  attention ê²°ê³¼ë¥¼ ë‹¤ì‹œ ê° expertì˜ ì°¨ì›ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë³µì›.
  - encoded [4,817,8,256]ë¥¼ ì• 784ê°œ/ë’¤ 33ê°œë¡œ ë¶„í• 
  - Expert 0: 8Ã—256 â†’ 2048  (PaliGemma ì›ë˜ ì°¨ì› ë³µì›)
  - Expert 1: 8Ã—256 â†’ 1024  (Action Expert ì›ë˜ ì°¨ì› ë³µì›)
  - ê° expertê°€ ì„œë¡œ ë‹¤ë¥¸ ì¶œë ¥ projection ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§
  - ì´ë¡œì¨ ê³µìœ  attention ì •ë³´ê°€ ê°ìì˜ í‘œí˜„ ê³µê°„ìœ¼ë¡œ ë§¤í•‘ë¨
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Step 7-6: Residual Connection

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:309-312` + `453-459`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 7-6: Residual Connection (Ï€â‚€ëŠ” gate ì—†ìŒ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _gated_residual(x, y, gate):
    if gate is None:
        return x + y  # Ï€â‚€: ì¼ë°˜ residual
    return x + y * gate  # Ï€â‚€.â‚…: gated residual (ë¯¸ì‚¬ìš©)

xs = [
    _gated_residual(xs[0], out[0], gates[0]),  # gate=None â†’ ë‹¨ìˆœ í•©
    _gated_residual(xs[1], out[1], gates[1]),  # gate=None â†’ ë‹¨ìˆœ í•©
]

# Expert 0 (Prefix):
# xs[0] = prefix_tokens + out[0]
# [4, 784, 2048] + [4, 784, 2048] = [4, 784, 2048]

# Expert 1 (Suffix):
# xs[1] = suffix_tokens + out[1]
# [4, 33, 1024] + [4, 33, 1024] = [4, 33, 1024]

# âœ… Output:
# xs[0]: [4, 784, 2048]
# xs[1]: [4, 33, 1024]

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 7-6 ìš”ì•½:
  Attention ì¶œë ¥ì„ ì›ë˜ ì…ë ¥ì— ë”í•˜ëŠ” ì²« ë²ˆì§¸ Residual Connection.
  - xs[i] = xs[i] + attn_out[i]  (ì›ë˜ ì •ë³´ + attentionìœ¼ë¡œ ì–»ì€ ìƒˆ ì •ë³´)
  - Residualì˜ ì—­í• : ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œ ê¸°ìš¸ê¸° ì†Œì‹¤ ë°©ì§€
    â†’ attentionì´ 0ì— ê°€ê¹Œì›Œë„ ì›ë˜ ì‹ í˜¸ê°€ ê·¸ëŒ€ë¡œ íë¦„
  - Ï€â‚€ëŠ” gate=None â†’ ë‹¨ìˆœ ë§ì…ˆ (Ï€â‚€.â‚…ëŠ” gateë¡œ ê°€ì¤‘ í•©ì‚°)
  - ë‘ expert ê°ê° ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰ (ì°¨ì› ìœ ì§€: 2048, 1024)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Step 7-7: FeedForward Network

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:314-330`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 7-7: FeedForward Network (Expertë³„ ë…ë¦½)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

for i, (x, config) in enumerate(zip(xs, configs)):
    if x is not None:
        # â”€â”€â”€ Pre-FFN RMSNorm â”€â”€â”€
        x_norm, gate = RMSNorm(name=_name("pre_ffw_norm", i))(x, None)
        # gate = None (Ï€â‚€)

        # â”€â”€â”€ GeGLU FeedForward â”€â”€â”€
        if i == 0:  # Expert 0 (PaliGemma)
            # width=2048, mlp_dim=16384
            w_gating = param((2, 2048, 16384))
            ff_gate = jnp.dot(x_norm, w_gating[0])   # [4, 784, 16384]
            ff1     = jnp.dot(x_norm, w_gating[1])   # [4, 784, 16384]
            activations = nn.gelu(ff_gate) * ff1       # [4, 784, 16384]
            w_linear = param((16384, 2048))
            outputs = jnp.dot(activations, w_linear)   # [4, 784, 2048]

        else:       # Expert 1 (Action Expert)
            # width=1024, mlp_dim=4096
            w_gating = param((2, 1024, 4096))
            ff_gate = jnp.dot(x_norm, w_gating[0])   # [4, 33, 4096]
            ff1     = jnp.dot(x_norm, w_gating[1])   # [4, 33, 4096]
            activations = nn.gelu(ff_gate) * ff1       # [4, 33, 4096]
            w_linear = param((4096, 1024))
            outputs = jnp.dot(activations, w_linear)   # [4, 33, 1024]

# â”€â”€â”€ Second Residual â”€â”€â”€
xs = [
    _gated_residual(xs[0], out[0], None),  # [4, 784, 2048]
    _gated_residual(xs[1], out[1], None),  # [4, 33, 1024]
]

# âœ… Output (Layer 0 ì™„ë£Œ):
# xs[0]: [4, 784, 2048]  (Prefix after full transformer block)
# xs[1]: [4, 33, 1024]   (Suffix after full transformer block)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 7-7 ìš”ì•½:
  Attention ì´í›„ ê° í† í°ì„ ë…ë¦½ì ìœ¼ë¡œ ë¹„ì„ í˜• ë³€í™˜í•˜ëŠ” FFN.
  - Expertë³„ ì™„ì „íˆ ë…ë¦½ì ì¸ ê°€ì¤‘ì¹˜ ì‚¬ìš©
  - Expert 0: 2048 â†’ 16384 â†’ 2048  (8ë°° í™•ì¥ í›„ ë³µì›)
  - Expert 1: 1024 â†’ 4096 â†’ 1024   (4ë°° í™•ì¥ í›„ ë³µì›)
  - GeGLU í™œì„±í™” (GELU gate Ã— linear): ì •ë³´ ì„ íƒì  í†µê³¼
  - ë‘ ë²ˆì§¸ Residual: xs[i] = xs[i] + ffn_out[i]
  - FFNì´ attentionì´ ì„ì–´ì˜¨ ì •ë³´ë¥¼ ê° expertì˜ "ê°œì¸ ì²˜ë¦¬"ë¡œ ì†Œí™”
  - Layer 0 ì™„ë£Œ â†’ Layer 1~17ë„ ë™ì¼ ê³¼ì • ë°˜ë³µ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 8: Transformer Layers 1-17

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:365-381` (nn.scan)

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 8: Repeat Layer 0 for Layers 1-17
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# nn.scanì„ ì‚¬ìš©í•˜ì—¬ 18ê°œ layerë¥¼ ìë™ìœ¼ë¡œ ë°˜ë³µ
# ê° layerëŠ” ë™ì¼í•œ êµ¬ì¡°, ë‹¤ë¥¸ weight

for layer_idx in range(1, 18):
    # Layer 0ê³¼ ë™ì¼í•œ ê³¼ì • ë°˜ë³µ:
    # 1. Pre-Attention RMSNorm (Expertë³„ ë…ë¦½ scale)
    # 2. QKV Projection (Expert 0: 2048â†’256, Expert 1: 1024â†’256)
    # 3. Q, K concat â†’ RoPE ì ìš©
    # 4. Grouped Query Attention (shared)
    # 5. Output Projection (Expert 0: 256â†’2048, Expert 1: 256â†’1024)
    # 6. Residual
    # 7. Pre-FFN RMSNorm
    # 8. FeedForward (Expert 0: 2048â†’16384â†’2048, Expert 1: 1024â†’4096â†’1024)
    # 9. Residual

    pass  # Automatically handled by nn.scan

# âœ… After 18 layers:
# xs[0]: [4, 784, 2048]  (Prefix, fully processed)
# xs[1]: [4, 33, 1024]   (Suffix, fully processed)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 8 ìš”ì•½:
  Layer 0ì˜ êµ¬ì¡°ë¥¼ 17ë²ˆ ë” ë°˜ë³µ (ì´ 18 layers).
  - ê° layerë§ˆë‹¤ ê³ ìœ í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§ (nn.scanìœ¼ë¡œ íš¨ìœ¨ì  êµ¬í˜„)
  - ë§¤ layerë§ˆë‹¤ prefixâ†”suffix ê°„ cross-attentionì´ ì¼ì–´ë‚¨
    â†’ ê¹Šì–´ì§ˆìˆ˜ë¡ ì´ë¯¸ì§€/ì–¸ì–´ ì •ë³´ê°€ action í† í°ì— ì ì  ë” ë…¹ì•„ë“¦
  - 18ì¸µì„ ê±°ì¹˜ë©´ì„œ action í† í°ì€ "í˜„ì¬ ê´€ì°°ì— ë§ëŠ” í–‰ë™ ì†ë„"ë¥¼ í‘œí˜„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 9: Final Layer Normalization

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/gemma.py:409-411`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 9: Final RMSNorm (Expertë³„)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

outputs = []
for i, (x, final_norm) in enumerate(zip(xs, self.final_norms)):
    if x is not None:
        x_final, _ = final_norm(x, None)  # adarms_cond=None (Ï€â‚€)
        outputs.append(x_final)

# âœ… Output:
# outputs[0]: [4, 784, 2048]  (Prefix final output)
# outputs[1]: [4, 33, 1024]   (Suffix final output)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 9 ìš”ì•½:
  18ê°œ Transformer layerë¥¼ ëª¨ë‘ í†µê³¼í•œ í›„ ë§ˆì§€ë§‰ ì •ê·œí™”.
  - ê° expertë§ˆë‹¤ ë…ë¦½ì ì¸ final RMSNorm ê°€ì¤‘ì¹˜ ì ìš©
  - ì´í›„ action ì˜ˆì¸¡ì—ë§Œ Suffix(Expert 1) ì¶œë ¥ì´ ì‚¬ìš©ë¨
  - Prefix(Expert 0) ì¶œë ¥ì€ í•™ìŠµ ì‹œì—ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
    (ì¶”ë¡  ì‹œì—ë„ KV Cacheì— ì´ë¯¸ ë°˜ì˜ë˜ì–´ ìˆì–´ ë³„ë„ ì²˜ë¦¬ ë¶ˆí•„ìš”)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 10: Velocity Prediction

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/pi0.py:212`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 10: Action Tokens â†’ Velocity Prediction
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# suffix_out: [4, 33, 1024]
# ë§ˆì§€ë§‰ action_horizon(32)ê°œ í† í°ë§Œ ì¶”ì¶œ (state í† í° ì œì™¸)
action_output = suffix_out[:, -32:]  # [4, 32, 1024]

# Project to action dimension
v_t = self.action_out_proj(action_output)
# Linear(1024 â†’ 7)
# v_t: [4, 32, 7]

# âœ… Output:
# v_t: [4, 32, 7]  (Predicted velocity field)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 10 ìš”ì•½:
  Transformerë¥¼ í†µê³¼í•œ action í† í°ì„ ì‹¤ì œ í–‰ë™ ì°¨ì›ìœ¼ë¡œ ë³€í™˜.
  - suffix_out[:, -32:]: 33ê°œ ì¤‘ ë§ˆì§€ë§‰ 32ê°œë§Œ ì¶”ì¶œ (state í† í° ì œì™¸)
  - Linear(1024â†’7): Action Expert ì°¨ì› â†’ ë¡œë´‡ DoF ì°¨ì›
  - ì¶œë ¥ v_tëŠ” Flow Matchingì—ì„œì˜ "ì†ë„(velocity)"
    = í˜„ì¬ x_tì—ì„œ ì–´ëŠ ë°©í–¥ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ì´ë™í•´ì•¼ í•˜ëŠ”ì§€
  - í•™ìŠµ: ì´ v_tì™€ ì •ë‹µ u_tì˜ ì°¨ì´ë¡œ loss ê³„ì‚°
  - ì¶”ë¡ : ì´ v_të¥¼ Euler stepì— ì‚¬ìš©í•˜ì—¬ x_të¥¼ ì—…ë°ì´íŠ¸
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Step 11: Flow Matching Loss

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/pi0.py:214`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 11: Compute Flow Matching Loss
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€ Target velocity â”€â”€â”€
u_t = noise - actions
# [4, 32, 7] - [4, 32, 7] = [4, 32, 7]
# ì§ì„  ê²½ë¡œì´ë¯€ë¡œ tì— ë¬´ê´€í•œ ìƒìˆ˜

# â”€â”€â”€ Loss â”€â”€â”€
loss = jnp.mean(jnp.square(v_t - u_t), axis=-1)
# MSE loss averaged over action dimensions
# loss: [4, 32]  (timestepë³„ loss)

# âœ… Output:
# loss: [4, 32] (training objective)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Step 11 ìš”ì•½:
  Flow Matching í•™ìŠµ ëª©í‘œ: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì†ë„ì™€ ì •ë‹µ ì†ë„ì˜ MSE.
  - ì •ë‹µ ì†ë„ u_t = noise - actions  (ì§ì„  ë³´ê°„ ê²½ë¡œì˜ ì ‘ì„  ë²¡í„°)
    tì™€ ë¬´ê´€í•œ ìƒìˆ˜ â†’ ì–´ë–¤ tì—ì„œ ìƒ˜í”Œë§í•´ë„ ë™ì¼í•œ ë°©í–¥
  - ì†ì‹¤ = ||v_t - u_t||^2  (L2 ê±°ë¦¬)
  - ì´ lossë¥¼ ì—­ì „íŒŒí•˜ë©´ ëª¨ë¸ì€ "noise â†’ data ë°©í–¥"ì„ í•™ìŠµ
  - í•™ìŠµ ì „ ê³¼ì •ì´ ë‹¨ 1ë²ˆì˜ forward passë¡œ ëë‚¨
    (ì´ìœ : ground truth actionsë¡œ ì§ì ‘ x_të¥¼ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“ Inference: Flow Matching Sampling

**ì½”ë“œ ìœ„ì¹˜**: `src/openpi/models/pi0.py:217-279`

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Inference: Iterative Denoising (Euler Integration)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def sample_actions(self, rng, observation, num_steps=10):
    # â”€â”€â”€ Step I-1: Prefix KV Cache ìƒì„± (í•œ ë²ˆë§Œ) â”€â”€â”€
    prefix_tokens, prefix_mask, prefix_ar_mask = self.embed_prefix(observation)
    prefix_attn_mask = make_attn_mask(prefix_mask, prefix_ar_mask)
    positions = jnp.cumsum(prefix_mask, axis=1) - 1

    _, kv_cache = self.PaliGemma.llm(
        [prefix_tokens, None],  # Expert 0ë§Œ ì²˜ë¦¬
        mask=prefix_attn_mask,
        positions=positions,
    )
    # kv_cache: 18 layers Ã— [4, 784, 1, 256]  â† ì €ì¥!

    # â”€â”€â”€ Step I-2: ì´ˆê¸°í™” â”€â”€â”€
    noise = jax.random.normal(rng, (4, 32, 7))
    x_t = noise  # time=1.0ì—ì„œ ì‹œì‘ (pure noise)
    dt = -1.0 / num_steps  # -0.1

    # â”€â”€â”€ Step I-3: Iterative Denoising â”€â”€â”€
    def step(carry):
        x_t, time = carry
        # time: 1.0 â†’ 0.9 â†’ 0.8 â†’ ... â†’ 0.1 â†’ 0.0

        # Suffix embedding (ë§¤ step x_t, timeì´ ë°”ë€Œë¯€ë¡œ ì¬ê³„ì‚°)
        suffix_tokens, suffix_mask, suffix_ar_mask, _ = \
            self.embed_suffix(observation, x_t, jnp.broadcast_to(time, [4]))
        # suffix_tokens: [4, 33, 1024]

        # Attention mask
        suffix_attn_mask = make_attn_mask(suffix_mask, suffix_ar_mask)
        prefix_attn_mask = einops.repeat(prefix_mask, "b p -> b s p", s=33)
        full_attn_mask = jnp.concatenate([prefix_attn_mask, suffix_attn_mask], axis=-1)
        # [4, 33, 817]

        # Positions
        positions = jnp.sum(prefix_mask, axis=-1)[:, None] + jnp.cumsum(suffix_mask, axis=-1) - 1

        # Transformer (Expert 1ë§Œ, KV cache ì¬ì‚¬ìš©!)
        (prefix_out, suffix_out), _ = self.PaliGemma.llm(
            [None, suffix_tokens],  # PrefixëŠ” None (cacheì—ì„œ ê°€ì ¸ì˜´)
            mask=full_attn_mask,
            positions=positions,
            kv_cache=kv_cache,  # â† ì €ì¥ëœ cache ì¬ì‚¬ìš©!
            adarms_cond=[None, None],
        )

        # Velocity ì˜ˆì¸¡
        v_t = self.action_out_proj(suffix_out[:, -32:])
        # Linear(1024 â†’ 7): [4, 32, 7]

        # Euler integration: x_{t+dt} = x_t + dt * v_t
        return x_t + dt * v_t, time + dt

    def cond(carry):
        x_t, time = carry
        return time >= -dt / 2  # time > 0

    # While loop (10 iterations)
    x_0, _ = jax.lax.while_loop(cond, step, (noise, 1.0))

    return x_0  # [4, 32, 7]  â† Denoised actions!

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ Inference ìš”ì•½:
  Pure noiseì—ì„œ ì‹œì‘í•˜ì—¬ Euler integrationìœ¼ë¡œ clean actionì„ ë³µì›.
  [Phase 1] Prefix KV Cache (1íšŒ ì‹¤í–‰):
    - ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ í† í°ì„ í•œ ë²ˆë§Œ Transformerì— í†µê³¼
    - 18 layers Ã— [4, 784, 1, 256] KV ê°’ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
    - ì¶”ë¡  ë‚´ë‚´ ê´€ì°°(ì´ë¯¸ì§€/ì–¸ì–´)ì€ ë³€í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¬ê³„ì‚° ë¶ˆí•„ìš”

  [Phase 2] Denoising Loop (10íšŒ ë°˜ë³µ):
    for t in [1.0, 0.9, ..., 0.1]:
      1. í˜„ì¬ x_tì™€ të¡œ suffix ì„ë² ë”© ì¬ìƒì„±  â† x_t, tê°€ ë§¤ë²ˆ ë°”ë€œ
      2. KV Cache + suffix í† í°ìœ¼ë¡œ Transformer ì‹¤í–‰ (Expert 1ë§Œ)
      3. v_t = ì˜ˆì¸¡ëœ ì†ë„  (í˜„ì¬ ìœ„ì¹˜ì—ì„œ data ë°©í–¥)
      4. x_{t+dt} = x_t + (-0.1) Ã— v_t  (Euler step)
    x_0 = ìµœì¢… action  (noise â†’ clean action)

  í•µì‹¬: prefix 1íšŒ + suffix 10íšŒ = ì´ 11íšŒ Transformer ì‹¤í–‰
        (ë§¤ë²ˆ ì „ì²´ ì¬ê³„ì‚°í•˜ë©´ 110íšŒ â†’ KV Cacheë¡œ 10ë°° ì ˆì•½)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“Š ì „ì²´ ë°ì´í„° íë¦„ ìš”ì•½

### Shape ë³€í™” ì¶”ì 

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Input Data                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Images:  3 Ã— [4, 224, 224, 3]  uint8 [0, 255]             â”‚
â”‚ State:   [4, 7]                float32                     â”‚
â”‚ Text:    [4, 16]               int32                       â”‚
â”‚ Actions: [4, 32, 7]            float32 (training)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Step 1: Preprocessing                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Images â†’ float32 [-1, 1]                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Step 2-4: Prefix Embedding                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Images:  3 Ã— [4, 256, 2048]    (SigLIP â†’ 2048 proj)       â”‚
â”‚ Text:    [4, 16, 2048]         (Embedder)                  â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚ Prefix:  [4, 784, 2048]        (Concatenated)              â”‚
â”‚          Expert 0 (PaliGemma 2B) ì²˜ë¦¬                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Step 5: Suffix Embedding                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ State:   [4, 7]  â†’ Linear(7â†’1024)        â†’ [4, 1, 1024]   â”‚
â”‚ Actions: [4,32,7]â†’ Linear(7â†’1024)        â†’ [4, 32, 1024]  â”‚
â”‚ Time:    [4]     â†’ sincos PE + MLP concat â†’ ì•¡ì…˜ì— í˜¼í•©     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚ Suffix:  [4, 33, 1024]    (state 1 + action 32)            â”‚
â”‚          Expert 1 (Action Expert 300M) ì²˜ë¦¬                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Step 6: Attention Mask Generation                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Mask:      [4, 817, 817]                                   â”‚
â”‚ Positions: [4, 817]                                        â”‚
â”‚                                                             â”‚
â”‚ ê·¸ë£¹:  prefix(0) â† state(1) â† action(2)                   â”‚
â”‚        prefixâ†”prefix ì–‘ë°©í–¥                                 â”‚
â”‚        actionâ†”action ì–‘ë°©í–¥                                 â”‚
â”‚        actionâ†’prefix/state ê°€ëŠ¥, prefixâ†’suffix ì°¨ë‹¨        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Step 7-8: Multi-Expert Transformer (18 layers)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ xs[0]: [4, 784, 2048] â”€â”€â†’ ... â”€â”€â†’ [4, 784, 2048]          â”‚
â”‚        Expert 0 (PaliGemma): QKV 2048â†’256, FFN 2048â†’16384  â”‚
â”‚                                                             â”‚
â”‚ xs[1]: [4, 33, 1024]  â”€â”€â†’ ... â”€â”€â†’ [4, 33, 1024]           â”‚
â”‚        Expert 1 (Action):   QKV 1024â†’256, FFN 1024â†’4096    â”‚
â”‚                                                             â”‚
â”‚ Attention: Q,K concat â†’ [4, 817, 8, 256] (ê³µìœ  ê³„ì‚°)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Step 9: Final Normalization                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Prefix:  [4, 784, 2048]                                    â”‚
â”‚ Suffix:  [4, 33, 1024]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Step 10: Velocity Prediction                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ suffix_out[:, -32:] â†’ Linear(1024â†’7) â†’ v_t: [4, 32, 7]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Step 11: Loss Computation                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ loss = mean_squared_error(v_t, u_t)                        â”‚
â”‚      = mean((v_t - (noise - actions))^2)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¥ í•µì‹¬ í¬ì¸íŠ¸

### 1. Multi-Expert ë©”ì»¤ë‹ˆì¦˜

```python
# Expert 0 (PaliGemma, width=2048):
# - "q_einsum":          [8, 2048, 256]
# - "kv_einsum":         [2, 1, 2048, 256]
# - "attn_vec_einsum":   [8, 256, 2048]
# - "mlp/gating_einsum": [2, 2048, 16384]
# - "mlp/linear":        [16384, 2048]

# Expert 1 (Action Expert, width=1024):
# - "q_einsum_1":          [8, 1024, 256]     â† ë‹¤ë¥¸ width!
# - "kv_einsum_1":         [2, 1, 1024, 256]
# - "attn_vec_einsum_1":   [8, 256, 1024]
# - "mlp/gating_einsum_1": [2, 1024, 4096]
# - "mlp/linear_1":        [4096, 1024]

# ê³µí†µ: head_dim=256, num_heads=8, num_kv_heads=1, depth=18
# â†’ ì„œë¡œ ë‹¤ë¥¸ ì°¨ì›ì˜ ì…ë ¥ì„ ê°™ì€ 256dimìœ¼ë¡œ projection í›„ attention ê³µìœ 
```

### 2. Ï€â‚€ Suffix êµ¬ì„±

```python
# state_proj: Linear(7 â†’ 1024) â†’ [4, 1, 1024]  (1ê°œ state í† í°)
# action_in_proj: Linear(7 â†’ 1024) â†’ [4, 32, 1024]
# time_emb: sincos PE â†’ [4, 1024]
#
# action + time ê²°í•© (MLP):
# concat([action_tokens, time_tokens]) â†’ [4, 32, 2048]
# â†’ action_time_mlp_in:  Linear(2048â†’1024) + SiLU
# â†’ action_time_mlp_out: Linear(1024â†’1024)
# â†’ [4, 32, 1024]
#
# suffix = concat([state_token, action_tokens]) â†’ [4, 33, 1024]
```

### 3. Flow Matching

```python
# Training:
time ~ Beta(1.5, 1.0)  # [0, 1], t=1 is noise, t=0 is data
x_t = time * noise + (1 - time) * actions
u_t = noise - actions  # Target velocity (ìƒìˆ˜)
loss = ||v_t - u_t||^2

# Inference (Euler integration):
x_t = noise  # t=1
for t in [1.0, 0.9, 0.8, ..., 0.1]:
    v_t = model(x_t, t)
    x_t = x_t + (-0.1) * v_t  # Euler step
# x_0 = clean actions
```

### 4. Attention Pattern

```
prefix(cumsum=0):  prefixë¼ë¦¬ ì–‘ë°©í–¥, suffixë¥¼ ë³¼ ìˆ˜ ì—†ìŒ
state(cumsum=1):   prefix ì°¸ì¡° ê°€ëŠ¥, actionì„ ë³¼ ìˆ˜ ì—†ìŒ
action(cumsum=2):  prefix + state + action ì „ë¶€ ì°¸ì¡° ê°€ëŠ¥ (ì–‘ë°©í–¥)
```

### 5. KV Cache Reuse (Inference)

```python
# Prefixë¥¼ í•œ ë²ˆë§Œ ì²˜ë¦¬:
_, kv_cache = llm([prefix_tokens, None], ...)
# 18 layers Ã— [4, 784, 1, 256] ì €ì¥

# 10ë²ˆ ë°˜ë³µí•  ë•Œë§ˆë‹¤ ì¬ì‚¬ìš©:
for step in range(10):
    _, _ = llm([None, suffix_tokens], kv_cache=kv_cache, ...)
    # PrefixëŠ” ì¬ê³„ì‚° ì•ˆ í•¨! â† 10ë°° ë¹ ë¦„
```

---

## ğŸ“ ë³€ê²½ ì´ë ¥

- 2026-02-08: ì´ˆì•ˆ ì‘ì„±
  - ì „ì²´ ë°ì´í„° íë¦„ Step-by-Step ì •ë¦¬
  - ê° ë‹¨ê³„ë³„ ìƒì„¸ ì½”ë“œ ì„¤ëª…
  - Shape ë³€í™” ì¶”ì 
  - í•µì‹¬ í¬ì¸íŠ¸ ì •ë¦¬

- 2026-02-14: Ï€â‚€ ì „ìš©ìœ¼ë¡œ ìˆ˜ì •
  - Ï€â‚€.â‚… AdaRMS ê´€ë ¨ ë‚´ìš© ì œê±°
  - Action Expert width 2048 â†’ 1024 ìˆ˜ì •
  - State í† í° ì¶”ê°€ (suffix 32 â†’ 33 í† í°)
  - Action+Time MLP ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
  - Attention mask ì°¨ì› 816 â†’ 817 ìˆ˜ì •
  - ì‹œê°í™” ë° ì„¤ëª… ì „ë°˜ ìˆ˜ì •

---

**ì‘ì„±ì**: AI Analysis
**í”„ë¡œì íŠ¸**: openpi (Physical Intelligence)
**ë²„ì „**: 2.0
